{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc4d1e5",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# NHẬN DẠNG 3 HÌNH: TRÒN, VUÔNG, TAM GIÁC\n",
    "# ===========================\n",
    "# Model này để nhận dạng chính xác hơn với ảnh nhiều màu và nhiều hình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cb99bb-7816-457f-b498-9c408f8901e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hàm detect_and_classify_shapes_improved!\n",
      "Hàm create_improved_gradio_interface()!\n",
      "Mặc định, hệ thống sẽ tự động chuyển ảnh sang grayscale (ảnh đen trắng) để xử lý!\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# HÀM TIỀN XỬ LÝ + DETECT CONTOUR BỔ SUNG\n",
    "# ===========================\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import gradio as gr\n",
    "\n",
    "def convert_to_grayscale(img):\n",
    "    if img is None:\n",
    "        return None\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def detect_shapes_improved(image_path_or_array, min_area=100, use_grayscale=True):\n",
    "    \n",
    "    # 1. Đọc ảnh (path hoặc array)\n",
    "    if isinstance(image_path_or_array, str):\n",
    "        img = cv2.imread(image_path_or_array)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Không đọc được ảnh: {image_path_or_array}\")\n",
    "    else:\n",
    "        img = image_path_or_array.copy()\n",
    "\n",
    "    # 2. Chuyển grayscale\n",
    "    if use_grayscale:\n",
    "        gray = convert_to_grayscale(img)\n",
    "    else:\n",
    "        # vẫn nên có grayscale để threshold\n",
    "        gray = convert_to_grayscale(img)\n",
    "\n",
    "    # 3. Giảm nhiễu\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 4. Threshold (adaptive + fallback Otsu)\n",
    "    try:\n",
    "        mask = cv2.adaptiveThreshold(\n",
    "            blurred, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            11, 2\n",
    "        )\n",
    "        if np.count_nonzero(mask) < 10:\n",
    "            _, mask = cv2.threshold(\n",
    "                blurred, 0, 255,\n",
    "                cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "            )\n",
    "    except Exception:\n",
    "        _, mask = cv2.threshold(\n",
    "            blurred, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "\n",
    "    # 5. Morphology để sạch nhiễu\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # 6. Tìm contour\n",
    "    contours_info = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours_info[0] if len(contours_info) == 2 else contours_info[1]\n",
    "\n",
    "    # 7. Lọc theo min_area\n",
    "    filtered = [c for c in contours if cv2.contourArea(c) >= max(1, min_area)]\n",
    "\n",
    "    return filtered, img, mask\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# HÀM NHẬN DẠNG CẢI THIỆN VỚI PREPROCESSING \n",
    "# ===========================\n",
    "def detect_and_classify_shapes_improved(image_path_or_array, model, img_size=None, min_area=100, use_grayscale=True, confidence_threshold=0.5):\n",
    "    # Detect model input shape\n",
    "    model_input_shape = model.input_shape[1:]  # Bỏ qua batch dimension\n",
    "    if len(model_input_shape) == 3:\n",
    "        # Format: (height, width, channels)\n",
    "        model_img_size = model_input_shape[0]\n",
    "        model_channels = model_input_shape[2]\n",
    "    elif len(model_input_shape) == 2:\n",
    "        # Format: (height, width) - grayscale\n",
    "        model_img_size = model_input_shape[0]\n",
    "        model_channels = 1\n",
    "    else:\n",
    "        # Fallback\n",
    "        model_img_size = 200 \n",
    "        model_channels = 1   # Grayscale\n",
    "    \n",
    "    if img_size is None:\n",
    "        img_size = model_img_size\n",
    "\n",
    "    if model_channels == 1:\n",
    "        use_grayscale = True\n",
    "        print(\"Model yêu cầu ảnh grayscale, tự động chuyển đổi...\")\n",
    "    \n",
    "    print(f\"Model input: {img_size}x{img_size}x{model_channels}\")\n",
    "\n",
    "    \n",
    "    contours, img, mask = detect_shapes_improved(\n",
    "        image_path_or_array,\n",
    "        min_area=min_area,\n",
    "        use_grayscale=use_grayscale\n",
    "    )\n",
    "    print(f\"Đã tìm thấy {len(contours)} contours\")\n",
    "    \n",
    "    # Lấy ảnh grayscale để dùng cho model prediction nếu model yêu cầu\n",
    "    if model_channels == 1:\n",
    "        img_gray = convert_to_grayscale(img)\n",
    "    else:\n",
    "        img_gray = None\n",
    "    \n",
    "    result_img = img.copy()\n",
    "    \n",
    "    # Tự động detect số classes từ model output shape\n",
    "    try:\n",
    "        dummy_input = np.zeros((1, img_size, img_size, model_channels), dtype='float32')\n",
    "        dummy_pred = model.predict(dummy_input, verbose=0)\n",
    "        num_classes = dummy_pred.shape[1] if len(dummy_pred.shape) > 1 else len(dummy_pred[0])\n",
    "    except:\n",
    "        num_classes = 3  # fallback\n",
    "    \n",
    "    # Labels dựa trên số classes\n",
    "    if num_classes == 3:\n",
    "        labels = ['circle', 'square', 'triangle']\n",
    "        labels_vn = ['Hinh tron', 'Hinh vuong', 'Tam giac']\n",
    "    else:\n",
    "        labels = [f'class_{i}' for i in range(num_classes)]\n",
    "        labels_vn = [f'Lớp {i}' for i in range(num_classes)]\n",
    "    \n",
    "    print(f\"Model có {num_classes} classes: {labels}\")\n",
    "    print(f\"Ngưỡng confidence: {confidence_threshold:.2f}, Min area: {min_area}\")\n",
    "    \n",
    "    detections = []\n",
    "    total_predictions = 0\n",
    "    low_confidence_count = 0\n",
    "    \n",
    "    # Duyệt qua contours\n",
    "    for contour in contours:\n",
    "        # Lấy bounding box với padding\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        padding = max(5, int(min(w, h) * 0.1))  # Padding động\n",
    "        \n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w = min(img.shape[1] - x, w + 2 * padding)\n",
    "        h = min(img.shape[0] - y, h + 2 * padding)\n",
    "        \n",
    "        # Crop ROI - sử dụng ảnh grayscale nếu model yêu cầu\n",
    "        if model_channels == 1 and img_gray is not None:\n",
    "            roi_gray_crop = img_gray[y:y+h, x:x+w]\n",
    "            if roi_gray_crop.size == 0:\n",
    "                continue\n",
    "            roi_resized = cv2.resize(roi_gray_crop, (img_size, img_size))\n",
    "            roi_normalized = roi_resized.reshape(1, img_size, img_size, 1).astype('float32') / 255.0\n",
    "        else:\n",
    "            roi_bgr = img[y:y+h, x:x+w]\n",
    "            if roi_bgr.size == 0:\n",
    "                continue\n",
    "            if model_channels == 3:\n",
    "                roi_rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)\n",
    "                roi_resized = cv2.resize(roi_rgb, (img_size, img_size))\n",
    "                roi_normalized = roi_resized.reshape(1, img_size, img_size, 3).astype('float32') / 255.0\n",
    "            else:\n",
    "                roi_gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                roi_resized = cv2.resize(roi_gray, (img_size, img_size))\n",
    "                roi_normalized = roi_resized.reshape(1, img_size, img_size, 1).astype('float32') / 255.0\n",
    "        \n",
    "        # Dự đoán\n",
    "        prediction = model.predict(roi_normalized, verbose=0)\n",
    "        \n",
    "        if len(prediction.shape) == 2:\n",
    "            pred_array = prediction[0]\n",
    "        else:\n",
    "            pred_array = prediction[0] if len(prediction) > 0 else prediction\n",
    "        \n",
    "        class_idx = np.argmax(pred_array)\n",
    "        confidence = float(pred_array[class_idx])\n",
    "        total_predictions += 1\n",
    "        \n",
    "        if class_idx >= len(labels):\n",
    "            print(f\"Warning: class_idx {class_idx} >= số classes {len(labels)}, bỏ qua\")\n",
    "            continue\n",
    "        \n",
    "        if confidence > confidence_threshold:\n",
    "            colors = {\n",
    "                0: (0, 255, 0),    # Circle - Xanh lá\n",
    "                1: (255, 0, 0),    # Square - Đỏ\n",
    "                2: (0, 0, 255)     # Triangle - Xanh dương\n",
    "            }\n",
    "            color = colors.get(class_idx, (128, 128, 128))\n",
    "            \n",
    "            cv2.rectangle(result_img, (x, y), (x + w, y + h), color, 3)\n",
    "            cv2.drawContours(result_img, [contour], -1, color, 2)\n",
    "            \n",
    "            label_text = f\"{labels_vn[class_idx]} {confidence:.2f}\"\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "            )\n",
    "            \n",
    "            cv2.rectangle(\n",
    "                result_img,\n",
    "                (x, y - text_height - 15),\n",
    "                (x + text_width + 10, y),\n",
    "                color,\n",
    "                -1\n",
    "            )\n",
    "            \n",
    "            cv2.putText(\n",
    "                result_img,\n",
    "                label_text,\n",
    "                (x + 5, y - 8),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (255, 255, 255),\n",
    "                2\n",
    "            )\n",
    "            \n",
    "            detections.append({\n",
    "                'x': int(x),\n",
    "                'y': int(y),\n",
    "                'w': int(w),\n",
    "                'h': int(h),\n",
    "                'class': labels[class_idx],\n",
    "                'class_vn': labels_vn[class_idx],\n",
    "                'confidence': float(confidence)\n",
    "            })\n",
    "        else:\n",
    "            low_confidence_count += 1\n",
    "            if confidence > 0.3:\n",
    "                print(f\"Hình bị bỏ qua: {labels[class_idx]} (confidence: {confidence:.2%} < {confidence_threshold:.2%})\")\n",
    "    \n",
    "    print(f\"\\nTổng kết: {total_predictions} hình được dự đoán, {len(detections)} hình được chấp nhận (confidence > {confidence_threshold:.2%})\")\n",
    "    if low_confidence_count > 0:\n",
    "        print(f\"   {low_confidence_count} hình bị bỏ qua do confidence thấp\")\n",
    "    \n",
    "    return result_img, detections\n",
    "\n",
    "print(\"Hàm detect_and_classify_shapes_improved!\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# TẠO GIAO DIỆN GRADIO CẢI THIỆN\n",
    "# ===========================\n",
    "_loaded_model = None\n",
    "\n",
    "def load_model_for_gradio(model_path=None):\n",
    "    global _loaded_model\n",
    "    \n",
    "    if _loaded_model is not None:\n",
    "        return _loaded_model\n",
    "    \n",
    "    default_models = [\n",
    "        \"shapes_3class_improved.h5\"\n",
    "    ]\n",
    "    \n",
    "    if model_path is None:\n",
    "        for model_file in default_models:\n",
    "            try:\n",
    "                _loaded_model = load_model(model_file)\n",
    "                print(f\"✅ Đã load model: {model_file}\")\n",
    "                return _loaded_model\n",
    "            except:\n",
    "                continue\n",
    "        raise FileNotFoundError(\"Không tìm thấy model nào. Vui lòng chỉ định đường dẫn model.\")\n",
    "    else:\n",
    "        _loaded_model = load_model(model_path)\n",
    "        print(f\"✅ Đã load model: {model_path}\")\n",
    "        return _loaded_model\n",
    "\n",
    "def predict_shape(image, model_path=None, use_grayscale=True):\n",
    "    global _loaded_model\n",
    "    \n",
    "    if image is None:\n",
    "        return None, \"Vui lòng upload ảnh\"\n",
    "    \n",
    "    try:\n",
    "        if _loaded_model is None:\n",
    "            load_model_for_gradio(model_path)\n",
    "        \n",
    "        # Gradio cho RGB → chuyển BGR\n",
    "        if len(image.shape) == 3:\n",
    "            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            image_bgr = image\n",
    "        \n",
    "        result_img, detections = detect_and_classify_shapes_improved(\n",
    "            image_bgr, \n",
    "            _loaded_model, \n",
    "            min_area=50,\n",
    "            use_grayscale=use_grayscale,\n",
    "            confidence_threshold=0.4\n",
    "        )\n",
    "        \n",
    "        result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        info_text = f\"Đã phát hiện {len(detections)} hình:\\n\"\n",
    "        for i, det in enumerate(detections, 1):\n",
    "            info_text += f\"{i}. {det['class_vn']} (độ tin cậy: {det['confidence']:.2%})\\n\"\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            info_text = \"Không phát hiện hình nào (độ tin cậy < 40%)\"\n",
    "        \n",
    "        return result_rgb, info_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Lỗi: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return None, error_msg\n",
    "\n",
    "def create_improved_gradio_interface(model_path=None):\n",
    "    try:\n",
    "        load_model_for_gradio(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Cảnh báo: {e}\")\n",
    "        print(\"Bạn có thể load model sau khi chạy interface\")\n",
    "    \n",
    "    with gr.Blocks(title=\"Nhận dạng hình dạng cải thiện\") as demo:\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Nhận dạng Hình Dạng\n",
    "            ### Upload ảnh để nhận dạng các hình: Tròn, Vuông, Tam giác\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(\n",
    "                    label=\"Upload ảnh\",\n",
    "                    type=\"numpy\",\n",
    "                    height=400\n",
    "                )\n",
    "                    \n",
    "                predict_btn = gr.Button(\"Nhận dạng\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                image_output = gr.Image(\n",
    "                    label=\"Kết quả nhận dạng\",\n",
    "                    type=\"numpy\",\n",
    "                    height=400\n",
    "                )\n",
    "                info_output = gr.Textbox(\n",
    "                    label=\"Thông tin\",\n",
    "                    lines=10,\n",
    "                    interactive=False\n",
    "                )\n",
    "        \n",
    "        predict_btn.click(\n",
    "            fn=lambda img: predict_shape(img, None, True),\n",
    "            inputs=[image_input],\n",
    "            outputs=[image_output, info_output]\n",
    "        )\n",
    "        \n",
    "        image_input.change(\n",
    "            fn=lambda img: predict_shape(img, None, True),\n",
    "            inputs=[image_input],\n",
    "            outputs=[image_output, info_output]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "print(\"Hàm create_improved_gradio_interface()!\")\n",
    "print(\"Mặc định, hệ thống sẽ tự động chuyển ảnh sang grayscale (ảnh đen trắng) để xử lý!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff4a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã load model: shapes_3class_improved.h5\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Giao diện Gradio đã chạy!\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 1️⃣6️⃣ CHẠY GIAO DIỆN GRADIO CẢI THIỆN\n",
    "# ===========================\n",
    "\n",
    "# Tạo và launch giao diện\n",
    "demo_improved = create_improved_gradio_interface()\n",
    "\n",
    "# Launch với các tùy chọn để tránh lỗi event loop\n",
    "demo_improved.launch()\n",
    "\n",
    "print(\"\\nGiao diện Gradio đã chạy!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
